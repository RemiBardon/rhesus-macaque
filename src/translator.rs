use openai_api_rs::v1::assistant::{AssistantRequest, AssistantObject};
use openai_api_rs::v1::common::GPT3_5_TURBO_1106;
use openai_api_rs::v1::api::Client;
use openai_api_rs::v1::message::{CreateMessageRequest, MessageRole};
use openai_api_rs::v1::run::CreateRunRequest;
use openai_api_rs::v1::thread::CreateThreadRequest;
use std::env;
use std::error::Error;
use std::time::Duration;

pub trait Translator {
    /// Name of the generator (eg. "gpt-3.5-turbo-1106", "GPT-4", "DeepL"â€¦).
    fn generator(&self) -> &str;

    /// Translate a text synchronously.
    fn translate_sync(
        &self,
        text: String,
        from_lang: String,
        to_lang: String,
        source_hash: String,
    ) -> Result<String, Box<dyn Error>>;

    /// Prompt sendable to a LLM for content translation.
    fn content_translate_prompt(
        &self,
        text: String,
        from_lang: String,
        to_lang: String,
        source_hash: String,
    ) -> String {
        format!(
            "Translate the following Hugo SSG markdown content file from {} to {}. Do not translate YAML items in `read_allowed` and `translationKey`. Add YAML front matter keys `translator: \"{}\"` and `sourceHash: \"{}\"` before all other keys and `# GENERATED BY {}` at the very top of the front matter. Remove italics from words in {} and add italics to words in {}.\n\n```md\n{}\n```",
            from_lang,
            to_lang,
            self.generator(),
            source_hash,
            self.generator(),
            to_lang,
            from_lang,
            text,
        )
    }
}

pub struct GPTManualTranslator {}

impl Translator for GPTManualTranslator {
    fn generator(&self) -> &str {
        todo!()
    }

    fn translate_sync(
        &self,
        text: String,
        from_lang: String,
        to_lang: String,
        source_hash: String,
    ) -> Result<String, Box<dyn Error>> {
        todo!()
    }
}

pub struct GPTAutoTranslator {
    client: Client,
    assistant: AssistantObject,
}

impl Translator for GPTAutoTranslator {
    fn generator(&self) -> &str {
        &self.assistant.model
    }

    fn translate_sync(
        &self,
        text: String,
        from_lang: String,
        to_lang: String,
        source_hash: String,
    ) -> Result<String, Box<dyn Error>> {
        let client = &self.client;
        let assistant = &self.assistant;

        let thread_req = CreateThreadRequest::new();
        let thread_result = client.create_thread(thread_req)?;
        println!("{:?}", thread_result.id.clone());

        let message_req = CreateMessageRequest::new(
            MessageRole::user,
            self.content_translate_prompt(text, from_lang, to_lang, source_hash),
        );

        let message_result = client.create_message(thread_result.id.clone(), message_req)?;
        println!("{:?}", message_result.id.clone());

        let run_req = CreateRunRequest::new(assistant.id.clone());
        let run_result = client.create_run(thread_result.id.clone(), run_req)?;

        loop {
            let run_result = client
                .retrieve_run(thread_result.id.clone(), run_result.id.clone())
                .unwrap();
            if run_result.status == "completed" {
                break;
            } else {
                println!("waiting...");
                std::thread::sleep(Duration::from_secs(1));
            }
        }

        let list_message_result = client.list_messages(thread_result.id.clone()).unwrap();
        let mut result = "".to_string();
        for data in list_message_result.data {
            for content in data.content {
                println!(
                    "{:?}: {:?} {:?}",
                    data.role, content.text.value, content.text.annotations
                );
                result.push_str(&content.text.value);
            }
        }

        Ok(result)
    }
}

impl GPTAutoTranslator {
    pub fn new() -> Result<Self, Box<dyn Error>> {
        dotenvy::dotenv()?;
        let api_key = env::var("OPENAI_API_KEY").expect("The `OPENAI_API_KEY` environment variable must be defined.");
        let model = match env::var("OPENAI_API_MODEL") {
            Ok(v) => v,
            Err(err) => {
                let model = GPT3_5_TURBO_1106.to_string();
                println!("`OPENAI_API_MODEL` environment variable not found ({}), using '{}'", err, model);
                model
            },
        };
        let description = env::var("OPENAI_ASSISTANT_DESCRIPTION").unwrap_or("Test assistant".to_string());

        let client = Client::new(api_key);

        let req = AssistantRequest::new(model)
            .description(description)
            .instructions("You are a personal math tutor. When asked a question, write and run Python code to answer the question.".to_string());
        println!("Assistant request: {:?}", req);

        let assistant = client.create_assistant(req)?;
        println!("Created assistant '{:?}'", assistant.id);

        Ok(Self { client, assistant })
    }
}
